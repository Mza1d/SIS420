{"cells":[{"cell_type":"markdown","metadata":{"id":"tfwOfkjclHQx"},"source":["# Ejercicio de programación Regresión Lineal Multiple"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":324,"status":"ok","timestamp":1655149218427,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"f0WGMMljlHQz"},"outputs":[],"source":["# utilizado para manejos de directorios y rutas\n","import os\n","\n","# Computacion vectorial y cientifica para python\n","import numpy as np\n","\n","# Librerias para graficación (trazado de gráficos)\n","from matplotlib import pyplot\n","from mpl_toolkits.mplot3d import Axes3D  # Necesario para graficar superficies 3D\n","import pandas as pd\n","import csv\n","# llama a matplotlib a embeber graficas dentro de los cuadernillos\n","%matplotlib inline"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>q1</th>\n","      <th>q2</th>\n","      <th>q3</th>\n","      <th>q4</th>\n","      <th>q5</th>\n","      <th>q6</th>\n","      <th>q7</th>\n","      <th>q8</th>\n","      <th>q9</th>\n","      <th>...</th>\n","      <th>q17</th>\n","      <th>q18</th>\n","      <th>q19</th>\n","      <th>q20</th>\n","      <th>q21</th>\n","      <th>q22</th>\n","      <th>q23</th>\n","      <th>q24</th>\n","      <th>q25</th>\n","      <th>q26</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>...</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","      <td>73.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>24.863014</td>\n","      <td>8.013699</td>\n","      <td>7.863014</td>\n","      <td>7.821918</td>\n","      <td>7.410959</td>\n","      <td>7.506849</td>\n","      <td>7.643836</td>\n","      <td>7.630137</td>\n","      <td>7.602740</td>\n","      <td>7.068493</td>\n","      <td>...</td>\n","      <td>8.068493</td>\n","      <td>7.452055</td>\n","      <td>7.465753</td>\n","      <td>7.410959</td>\n","      <td>7.589041</td>\n","      <td>7.808219</td>\n","      <td>7.561644</td>\n","      <td>7.479452</td>\n","      <td>7.561644</td>\n","      <td>7.328767</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>12.484785</td>\n","      <td>2.195280</td>\n","      <td>1.953025</td>\n","      <td>2.231980</td>\n","      <td>2.040123</td>\n","      <td>1.764805</td>\n","      <td>2.002567</td>\n","      <td>1.961482</td>\n","      <td>1.905691</td>\n","      <td>2.281135</td>\n","      <td>...</td>\n","      <td>2.070485</td>\n","      <td>2.041521</td>\n","      <td>2.297838</td>\n","      <td>2.178402</td>\n","      <td>2.408524</td>\n","      <td>2.189987</td>\n","      <td>2.471989</td>\n","      <td>2.298004</td>\n","      <td>2.279049</td>\n","      <td>2.333659</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>19.000000</td>\n","      <td>7.000000</td>\n","      <td>7.000000</td>\n","      <td>7.000000</td>\n","      <td>6.000000</td>\n","      <td>7.000000</td>\n","      <td>7.000000</td>\n","      <td>7.000000</td>\n","      <td>7.000000</td>\n","      <td>6.000000</td>\n","      <td>...</td>\n","      <td>7.000000</td>\n","      <td>6.000000</td>\n","      <td>6.000000</td>\n","      <td>6.000000</td>\n","      <td>7.000000</td>\n","      <td>7.000000</td>\n","      <td>6.000000</td>\n","      <td>7.000000</td>\n","      <td>7.000000</td>\n","      <td>6.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>20.000000</td>\n","      <td>9.000000</td>\n","      <td>8.000000</td>\n","      <td>9.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>7.000000</td>\n","      <td>...</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>29.000000</td>\n","      <td>10.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>...</td>\n","      <td>10.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>10.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","      <td>9.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>55.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>...</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 27 columns</p>\n","</div>"],"text/plain":["             age         q1         q2         q3         q4         q5  \\\n","count  73.000000  73.000000  73.000000  73.000000  73.000000  73.000000   \n","mean   24.863014   8.013699   7.863014   7.821918   7.410959   7.506849   \n","std    12.484785   2.195280   1.953025   2.231980   2.040123   1.764805   \n","min     1.000000   1.000000   1.000000   1.000000   2.000000   2.000000   \n","25%    19.000000   7.000000   7.000000   7.000000   6.000000   7.000000   \n","50%    20.000000   9.000000   8.000000   9.000000   8.000000   8.000000   \n","75%    29.000000  10.000000   9.000000   9.000000   9.000000   9.000000   \n","max    55.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n","\n","              q6         q7         q8         q9  ...        q17        q18  \\\n","count  73.000000  73.000000  73.000000  73.000000  ...  73.000000  73.000000   \n","mean    7.643836   7.630137   7.602740   7.068493  ...   8.068493   7.452055   \n","std     2.002567   1.961482   1.905691   2.281135  ...   2.070485   2.041521   \n","min     2.000000   1.000000   2.000000   1.000000  ...   1.000000   1.000000   \n","25%     7.000000   7.000000   7.000000   6.000000  ...   7.000000   6.000000   \n","50%     8.000000   8.000000   8.000000   7.000000  ...   8.000000   8.000000   \n","75%     9.000000   9.000000   9.000000   9.000000  ...  10.000000   9.000000   \n","max    10.000000  10.000000  10.000000  10.000000  ...  10.000000  10.000000   \n","\n","             q19        q20        q21        q22        q23        q24  \\\n","count  73.000000  73.000000  73.000000  73.000000  73.000000  73.000000   \n","mean    7.465753   7.410959   7.589041   7.808219   7.561644   7.479452   \n","std     2.297838   2.178402   2.408524   2.189987   2.471989   2.298004   \n","min     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n","25%     6.000000   6.000000   7.000000   7.000000   6.000000   7.000000   \n","50%     8.000000   8.000000   8.000000   8.000000   8.000000   8.000000   \n","75%     9.000000   9.000000   9.000000   9.000000  10.000000   9.000000   \n","max    10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n","\n","             q25        q26  \n","count  73.000000  73.000000  \n","mean    7.561644   7.328767  \n","std     2.279049   2.333659  \n","min     1.000000   1.000000  \n","25%     7.000000   6.000000  \n","50%     8.000000   8.000000  \n","75%     9.000000   9.000000  \n","max    10.000000  10.000000  \n","\n","[8 rows x 27 columns]"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv(\"./DataSet/survey.csv\", delimiter=',')\n","data.describe()"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["x\n","     q1  q4  q23\n","0    9   6    5\n","1   10   9   10\n","2   10  10    9\n","3    5   5   10\n","4    9  10   10\n","..  ..  ..  ...\n","68   9   9    5\n","69   8   9    6\n","70  10   6    1\n","71  10  10   10\n","72   1   2   10\n","\n","[73 rows x 3 columns] y\n"," 0      3\n","1      8\n","2      8\n","3      6\n","4     10\n","      ..\n","68     5\n","69     6\n","70     1\n","71    10\n","72    10\n","Name: q26, Length: 73, dtype: int64\n"]}],"source":["#data = pd.read_csv(\"./DataSet/survey.csv\", delimiter=';', skiprows=1)\n","#data = np.loadtxt('./DataSet/survey.csv', delimiter=',', skiprows=1,)\n","data = pd.read_csv(\"./DataSet/survey.csv\", delimiter=',')\n","data1 = pd.DataFrame(data)\n","X = data1[[\"q1\",\"q4\",\"q23\"]]\n","y = data[\"q26\"]\n","print(\"x\\n\", X, \"y\\n\",y)\n","m = y.size"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["def graficarDatos(x, y):\n","    fig = pyplot.figure()\n","    pyplot.plot(x, y, 'ro')\n","    pyplot.xlabel('y')\n","    pyplot.ylabel(' x')"]},{"cell_type":"markdown","metadata":{"id":"G6-ykOwelHQ0"},"source":["## 2 Regresión lineal con multiples variables\n","\n","Se implementa la regresion lineal multivariable para predecir el precio de las casas. El archivo `Datasets/ex1data2.txt` contiene un conjunto de entrenamiento de precios de casas en Portland, Oregon. La primera columna es el tamaño de la casa en metros cuadrados, la segunda columna es el numero de cuartos, y la tercera columna es el precio de la casa. \n","\n","<a id=\"section4\"></a>\n","### 2.1 Normalización de caracteristicas\n","\n","Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente."]},{"cell_type":"markdown","metadata":{"id":"7iU_3mwZlHQ1"},"source":["La desviación estándar es una forma de medir cuánta variación hay en el rango de valores de una característica en particular (la mayoría de los puntos caeran en un rango de ± 2 en relación a la desviaciones estándar de la media); esta es una alternativa a tomar el rango de valores (max-min). En `numpy`, se puede usar la función `std` para calcular la desviacion estandar. \n","\n","Por ejemplo, la caracteristica`X[:, 0]` contiene todos los valores de $x_1$ (tamaño de las casas) en el conjunto de entrenamiento, entonces `np.std(X[:, 0])` calcula la desviacion estandar de los tamaños de las casas.\n","En el momento en que se llama a la función `featureNormalize`, la columna adicional de unos correspondiente a $ x_0 = 1 $ aún no se ha agregado a $ X $. \n","\n","<div class=\"alert alert-block alert-warning\">\n","**Notas para la implementación:** Cuando se normalize una caracteristica, es importante almacenar los valores usados para la normalización - el valor de la media y el valor de la desviación estandar usado para los calculos. Despues de aprender los parametros del modelo, se deseara predecir los precios de casas que no se han visto antes. Dado un nuevo valor de x (area del living room y el numero de dormitorios), primero se debe normalizar x usando la media y la desviacion estandar que se empleo anteriormente en el conjunto de entrenamiento para entrenar el modelo.\n","</div>\n","<a id=\"featureNormalize\"></a>"]},{"cell_type":"code","execution_count":79,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1655150574720,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"7xFD8H3WlHQ1"},"outputs":[],"source":["def  featureNormalize(X):\n","    X_norm = X.copy()\n","    mu = np.zeros(X.shape[1])\n","    sigma = np.zeros(X.shape[1])\n","\n","    mu = np.mean(X, axis = 0)\n","    sigma = np.std(X, axis = 0)\n","    X_norm = (X - mu) / sigma\n","    \n","    return X_norm, mu, sigma"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1655150587621,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"ipL_QsTZlHQ2","outputId":"3acd77c0-8d93-40d6-c4b2-28cbf45f52e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Media calculada: q1     8.013699\n","q4     7.410959\n","q23    7.561644\n","dtype: float64\n","Desviación estandar calculada: q1     2.180192\n","q4     2.026101\n","q23    2.454999\n","dtype: float64\n"]}],"source":["# llama featureNormalize con los datos cargados\n","X_norm, mu, sigma = featureNormalize(X)\n","\n","#print(X)\n","print('Media calculada:', mu)\n","print('Desviación estandar calculada:', sigma)\n","#print(X_norm)"]},{"cell_type":"markdown","metadata":{"id":"it9bMYuLlHQ2"},"source":["Despues de `featureNormalize` la funcion es provada, se añade el temino de interseccion a `X_norm`:"]},{"cell_type":"code","execution_count":81,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1655150615564,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"nNaGVxgolHQ2"},"outputs":[],"source":["# Añade el termino de interseccion a X\n","# (Columna de unos para X0)\n","X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"]},{"cell_type":"code","execution_count":82,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1655150621252,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"nbUVohnhlHQ3","outputId":"9d0153e8-b28f-4b48-8cac-acfae1a950e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 1.          0.45239198 -0.69639119 -1.04343971]\n"," [ 1.          0.91106719  0.78428522  0.99322068]\n"," [ 1.          0.91106719  1.27784403  0.58588861]\n"," [ 1.         -1.38230884 -1.18994999  0.99322068]\n"," [ 1.          0.45239198  1.27784403  0.99322068]\n"," [ 1.          0.91106719  0.78428522  0.99322068]\n"," [ 1.         -0.00628322 -0.69639119 -1.04343971]\n"," [ 1.          0.45239198 -0.69639119 -2.26543594]\n"," [ 1.         -0.00628322  0.78428522  0.58588861]\n"," [ 1.         -0.46495843 -0.20283239 -0.22877555]\n"," [ 1.          0.45239198  0.29072642  0.58588861]\n"," [ 1.          0.91106719  1.27784403  0.99322068]\n"," [ 1.          0.91106719  0.29072642  0.99322068]\n"," [ 1.          0.91106719 -0.69639119  0.99322068]\n"," [ 1.          0.91106719  0.29072642  0.99322068]\n"," [ 1.          0.91106719  1.27784403  0.58588861]\n"," [ 1.         -1.84098405 -1.6835088  -1.45077179]\n"," [ 1.          0.45239198 -0.20283239 -0.22877555]\n"," [ 1.         -0.00628322  0.78428522 -0.22877555]\n"," [ 1.         -0.46495843  0.29072642 -0.22877555]\n"," [ 1.          0.45239198  0.78428522  0.17855653]\n"," [ 1.          0.91106719 -0.20283239  0.17855653]\n"," [ 1.         -2.29965925  0.78428522  0.58588861]\n"," [ 1.          0.45239198  0.78428522  0.58588861]\n"," [ 1.         -0.00628322 -1.18994999 -2.67276802]\n"," [ 1.         -0.92363364 -0.69639119  0.99322068]\n"," [ 1.          0.91106719  0.29072642 -0.22877555]\n"," [ 1.         -0.00628322  0.29072642  0.17855653]\n"," [ 1.          0.45239198  0.29072642  0.17855653]\n"," [ 1.         -0.46495843 -0.69639119 -0.63610763]\n"," [ 1.          0.91106719  1.27784403 -0.63610763]\n"," [ 1.         -0.00628322 -1.6835088   0.58588861]\n"," [ 1.         -0.92363364 -1.6835088  -0.22877555]\n"," [ 1.          0.45239198  0.78428522  0.99322068]\n"," [ 1.         -0.92363364 -0.20283239  0.17855653]\n"," [ 1.         -1.38230884 -0.20283239 -1.85810386]\n"," [ 1.          0.91106719  0.29072642 -0.63610763]\n"," [ 1.         -0.46495843 -0.69639119 -0.22877555]\n"," [ 1.         -0.00628322 -2.1770676   0.99322068]\n"," [ 1.         -0.92363364 -0.69639119 -0.22877555]\n"," [ 1.          0.45239198  0.78428522 -2.67276802]\n"," [ 1.          0.45239198  1.27784403  0.99322068]\n"," [ 1.         -0.00628322 -1.6835088   0.58588861]\n"," [ 1.         -0.00628322 -0.20283239  0.99322068]\n"," [ 1.          0.91106719  1.27784403  0.99322068]\n"," [ 1.          0.45239198  0.78428522 -0.22877555]\n"," [ 1.         -0.00628322 -0.20283239  0.17855653]\n"," [ 1.         -0.46495843 -0.20283239 -0.22877555]\n"," [ 1.         -0.00628322  0.29072642 -1.04343971]\n"," [ 1.         -0.00628322  1.27784403  0.17855653]\n"," [ 1.         -3.21700967 -2.1770676  -2.26543594]\n"," [ 1.          0.45239198 -0.20283239 -1.04343971]\n"," [ 1.          0.91106719  0.78428522  0.58588861]\n"," [ 1.         -0.00628322 -0.20283239 -0.63610763]\n"," [ 1.          0.45239198  0.78428522  0.58588861]\n"," [ 1.         -0.92363364  1.27784403  0.99322068]\n"," [ 1.         -0.00628322 -0.69639119  0.17855653]\n"," [ 1.          0.45239198  0.29072642 -0.63610763]\n"," [ 1.          0.91106719  0.29072642  0.99322068]\n"," [ 1.          0.91106719  1.27784403  0.17855653]\n"," [ 1.         -1.84098405 -2.1770676   0.99322068]\n"," [ 1.         -0.46495843 -1.18994999 -1.04343971]\n"," [ 1.          0.45239198 -0.69639119  0.58588861]\n"," [ 1.          0.45239198  0.78428522  0.58588861]\n"," [ 1.          0.91106719  0.78428522  0.99322068]\n"," [ 1.         -3.21700967 -0.69639119 -1.04343971]\n"," [ 1.         -0.46495843  0.78428522 -0.22877555]\n"," [ 1.          0.91106719 -0.69639119  0.99322068]\n"," [ 1.          0.45239198  0.78428522 -1.04343971]\n"," [ 1.         -0.00628322  0.78428522 -0.63610763]\n"," [ 1.          0.91106719 -0.69639119 -2.67276802]\n"," [ 1.          0.91106719  1.27784403  0.99322068]\n"," [ 1.         -3.21700967 -2.6706264   0.99322068]]\n"]}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"id":"xzLiIE6NlHQ3"},"source":["<a id=\"section5\"></a>\n","### 2.2 Descenso por el gradiente\n","\n","En el ejemplo anterior se implemento el descenso por el gradiente para un problema de regresion univariable. La unica diferencia es que ahora existe una caracteristica adicional en la matriz $X$. La función de hipótesis y la regla de actualización del descenso del gradiente por lotes permanecen sin cambios.\n","\n","La implementacion de las funciones `computeCostMulti` y `gradientDescentMulti` son similares a la funcion de costo y función de descenso por el gradiente de la regresión lineal multiple es similar al de la regresion lineal multivariable. Es importante garantizar que el codigo soporte cualquier numero de caracteristicas y esten bien vectorizadas.\n","\n","Se puede utilizar `shape`, propiedad de los arrays `numpy`, para identificar cuantas caracteristicas estan consideradas en el dataset.\n","\n","<div class=\"alert alert-block alert-warning\">\n","**Nota de implementación:** En el caso de multivariables, la función de costo puede se escrita considerando la forma vectorizada de la siguiente manera:\n","\n","$$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$\n","\n","donde:\n","\n","$$ X = \\begin{pmatrix}\n","          - (x^{(1)})^T - \\\\\n","          - (x^{(2)})^T - \\\\\n","          \\vdots \\\\\n","          - (x^{(m)})^T - \\\\ \\\\\n","        \\end{pmatrix} \\qquad \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\\\\\end{bmatrix}$$\n","\n","La version vectorizada es eficiente cuando se trabaja con herramientas de calculo numericos computacional como `numpy`. \n","</div>\n","\n","<a id=\"computeCostMulti\"></a>"]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1655150648732,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"EQCMN7KqlHQ3"},"outputs":[],"source":["def computeCostMulti(X, y, theta):\n","    # Inicializa algunos valores utiles\n","    m = y.shape[0] # numero de ejemplos de entrenamiento\n","    \n","    J = 0\n","    \n","    h = np.dot(X, theta)\n","    \n","    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))\n","    \n","    return J\n"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":304,"status":"ok","timestamp":1655150654938,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Vdy_aQUklHQ4"},"outputs":[],"source":["def gradientDescentMulti(X, y, theta, alpha, num_iters):\n","    \n","    # Inicializa algunos valores \n","    m = y.shape[0] # numero de ejemplos de entrenamiento\n","    \n","    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n","    theta = theta.copy()\n","    \n","    J_history = []\n","    \n","    for i in range(num_iters):\n","        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)\n","        J_history.append(computeCostMulti(X, y, theta))\n","    \n","    return theta, J_history"]},{"cell_type":"markdown","metadata":{"id":"a8b_GwZslHQ4"},"source":["#### 3.2.1 Seleccionando coheficientes de aprendizaje\n"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"elapsed":873,"status":"ok","timestamp":1655150665940,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"sId0DiH9lHQ4","outputId":"8f495b1a-d56b-4474-ca6b-00de72a0eee9"},"outputs":[{"name":"stdout","output_type":"stream","text":["theta calculado por el descenso por el gradiente: [7.32876712 0.14542051 0.05668689 1.73451104]\n","(usando el descenso por el gradiente)\n"," El sitio web es recomendable a: 7 amigos\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Elegir algun valor para alpha (probar varias alternativas)\n","alpha = 0.003 # alpha = 0.003\n","num_iters = 10000\n","\n","# inicializa theta y ejecuta el descenso por el gradiente\n","theta = np.zeros(4)\n","theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)\n","\n","# Grafica la convergencia del costo\n","pyplot.plot(np.arange(len(J_history)), J_history, lw=2)\n","pyplot.xlabel('Numero de iteraciones')\n","pyplot.ylabel('Costo J')\n","\n","# Muestra los resultados del descenso por el gradiente\n","print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))\n","\n","# Estimar a cuantas personas cuantas amigos personas se pueden recomendar el sitio web\n","X_array = [1, 3, 1, 8]\n","X_array[1:4] = (X_array[1:4] - mu) / sigma\n","predit = np.dot(X_array, theta)   # Se debe cambiar esto\n","\n","print('(usando el descenso por el gradiente)\\n El sitio web es recomendable a: {:.0f}'.format(predit), 'amigos')"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"y0aZhWEqlHQ4"},"outputs":[],"source":["X_array = [1, 10, 3, 4]\n","X_array[1:4] = (X_array[1:4] - mu) / sigma"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"KZ4G9CbJlHQ4","outputId":"129fb7ac-fbc2-4f63-d94b-70e24c72a06b"},"outputs":[{"data":{"text/plain":["[0.911067191137229, -2.177067599204224, -1.4507717862449523]"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["X_array[1:4]"]},{"cell_type":"markdown","metadata":{"id":"-nMzqD8elHQ4"},"source":["<a id=\"section7\"></a>\n","### 2.3 Ecuacion de la Normal\n","\n","Una manera de calcular rapidamente el modelo de una regresion lineal es:\n","\n","$$ \\theta = \\left( X^T X\\right)^{-1} X^T\\vec{y}$$\n","\n","Utilizando esta formula no requiere que se escale ninguna caracteristica, y se obtendra una solucion exacta con un solo calculo: no hay “bucles de convergencia” como en el descenso por el gradiente. \n","\n","Primero se recargan los datos para garantizar que las variables no esten modificadas. Recordar que no es necesario escalar las caracteristicas, se debe agregar la columna de unos a la matriz $X$ para tener el termino de intersección($\\theta_0$). "]},{"cell_type":"code","execution_count":98,"metadata":{"executionInfo":{"elapsed":316,"status":"ok","timestamp":1655150828677,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"C6j77JNmlHQ5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 1.  4.  5.]\n"," [ 1. 10. 10.]\n"," [ 1.  9.  9.]\n"," [ 1.  9. 10.]\n"," [ 1.  9. 10.]\n"," [ 1.  4. 10.]\n"," [ 1.  6.  5.]\n"," [ 1. 10.  2.]\n"," [ 1.  8.  9.]\n"," [ 1.  8.  7.]\n"," [ 1.  9.  9.]\n"," [ 1. 10. 10.]\n"," [ 1.  9. 10.]\n"," [ 1.  9. 10.]\n"," [ 1. 10. 10.]\n"," [ 1.  8.  9.]\n"," [ 1.  4.  4.]\n"," [ 1.  6.  7.]\n"," [ 1.  9.  7.]\n"," [ 1.  8.  7.]\n"," [ 1.  9.  8.]\n"," [ 1. 10.  8.]\n"," [ 1.  8.  9.]\n"," [ 1.  8.  9.]\n"," [ 1.  5.  1.]\n"," [ 1.  7. 10.]\n"," [ 1.  9.  7.]\n"," [ 1.  7.  8.]\n"," [ 1.  9.  8.]\n"," [ 1.  7.  6.]\n"," [ 1.  5.  6.]\n"," [ 1.  7.  9.]\n"," [ 1.  7.  7.]\n"," [ 1.  9. 10.]\n"," [ 1.  7.  8.]\n"," [ 1.  5.  3.]\n"," [ 1.  7.  6.]\n"," [ 1. 10.  7.]\n"," [ 1.  7. 10.]\n"," [ 1.  7.  7.]\n"," [ 1.  7.  1.]\n"," [ 1. 10. 10.]\n"," [ 1.  9.  9.]\n"," [ 1.  9. 10.]\n"," [ 1. 10. 10.]\n"," [ 1.  6.  7.]\n"," [ 1.  8.  8.]\n"," [ 1.  6.  7.]\n"," [ 1.  6.  5.]\n"," [ 1.  9.  8.]\n"," [ 1.  1.  2.]\n"," [ 1.  7.  5.]\n"," [ 1.  7.  9.]\n"," [ 1.  5.  6.]\n"," [ 1.  9.  9.]\n"," [ 1. 10. 10.]\n"," [ 1.  9.  8.]\n"," [ 1.  7.  6.]\n"," [ 1.  9. 10.]\n"," [ 1.  8.  8.]\n"," [ 1.  9. 10.]\n"," [ 1.  5.  5.]\n"," [ 1.  7.  9.]\n"," [ 1.  7.  9.]\n"," [ 1. 10. 10.]\n"," [ 1. 10.  5.]\n"," [ 1.  8.  7.]\n"," [ 1.  8. 10.]\n"," [ 1.  8.  5.]\n"," [ 1.  5.  6.]\n"," [ 1.  7.  1.]\n"," [ 1. 10. 10.]\n"," [ 1.  6. 10.]]\n"]}],"source":["# Cargar datos\n","data = pd.read_csv(\"./DataSet/survey.csv\")\n","data1 = pd.DataFrame(data)\n","X = data[[\"q14\",\"q23\"]]\n","y = data[\"age\"]\n","m = y.size\n","X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","print(X)"]},{"cell_type":"code","execution_count":99,"metadata":{"executionInfo":{"elapsed":324,"status":"ok","timestamp":1655150861144,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"gVZdjjk9lHQ5"},"outputs":[],"source":["def normalEqn(X, y):\n","  \n","    theta = np.zeros(X.shape[1])\n","    \n","    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)\n","    \n","    return theta"]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1655150868173,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Ybyw-FfolHQ5","outputId":"af046db4-efd0-440a-c49f-2053dfc4b3da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Theta calculado a partir de la ecuación de la normal: [36.27895976 -1.6143258   0.13092882]\n","Edad predecido en la satisfación del sitio web : 25 anos\n"]}],"source":["# Calcula los parametros con la ecuación de la normal\n","theta = normalEqn(X, y);\n","\n","# Muestra los resultados optenidos a partir de la aplicación de la ecuación de la normal\n","print('Theta calculado a partir de la ecuación de la normal: {:s}'.format(str(theta)));\n","\n","# Estimar el precio para una casa de superficie de 1650 sq-ft y tres dormitorios\n","\n","X_array = [1, 8, 10]\n","predit = np.dot(X_array, theta) \n","\n","print('Edad predecido en la satisfación del sitio web : {:.0f}'.format(predit), \"anos\")"]}],"metadata":{"colab":{"name":"reg_lin_mul_01.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"4fc575347efa219798fdc80e72f18537acafed02733d7815abe9dda575f05009"}}},"nbformat":4,"nbformat_minor":0}
